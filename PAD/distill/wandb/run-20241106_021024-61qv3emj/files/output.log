Distributed training:  False
Hyper-parameters:
 {'cfg': '../configs/MNIST/IPC1.yaml', 'dataset': 'MNIST', 'subset': 'imagenette', 'model': 'ConvNet', 'ipc': 1, 'eval_mode': 'S', 'num_eval': 1, 'eval_it': 500, 'epoch_eval_train': 1000, 'Iteration': 5000, 'lr_img': 100, 'lr_teacher': 0.01, 'lr_init': 0.01, 'batch_real': 256, 'batch_syn': 500, 'batch_train': 128, 'pix_init': 'samples_predicted_correctly', 'dsa': True, 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '../dataset', 'buffer_path': '../buffer_storage/', 'expert_epochs': 1, 'syn_steps': 40, 'max_start_epoch': 4, 'min_start_epoch': 0, 'zca': True, 'load_all': False, 'no_aug': False, 'texture': False, 'canvas_size': 2, 'canvas_samples': 1, 'max_files': None, 'max_experts': None, 'force_save': False, 'ema_decay': 0.995, 'lr_y': 5.0, 'Momentum_y': 0.9, 'project': 'MNIST_ipc1', 'name': 'RANDOM', 'threshold': 1.05, 'loss_ratio': 0.25, 'depth_ratio': 0.25, 'record_loss': False, 'Sequential_Generation': True, 'expansion_end_epoch': 3000, 'current_max_start_epoch': 20, 'init_frozen': 'start', 'skip_first_eva': True, 'parall_eva': False, 'lr_lr': 1e-07, 'res': 32, 'device': 'cuda', 'Initialize_Label_With_Another_Model': False, 'Initialize_Label_Model': '', 'Initialize_Label_Model_Dir': '', 'Label_Model_Timestamp': -1, 'zca_trans': ZCAWhitening(), 'im_size': [28, 28], 'dc_aug_param': None, 'dsa_param': <utils.utils_baseline.ParamDiffAug object at 0x00000206DDC727D0>, '_wandb': {}, 'distributed': False}
Evaluation model pool:  ['ConvNet']
BUILDING DATASET
  0%|                                                                                                                                                                                                  | 0/60000 [00:00<?, ?it/s]D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_loss.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels_all.append(class_map[torch.tensor(sample[1]).item()])
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60000/60000 [00:00<00:00, 70995.24it/s]
60000it [00:00, 1064431.60it/s]
class c = 0: 5923 real images
class c = 1: 6742 real images
class c = 2: 5958 real images
class c = 3: 6131 real images
class c = 4: 5842 real images
class c = 5: 5421 real images
class c = 6: 5918 real images
class c = 7: 6265 real images
class c = 8: 5851 real images
class c = 9: 5949 real images
real images channel 0, mean = -0.0000, std = 0.5891
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_loss.py:137: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\torch\csrc\utils\tensor_new.cpp:281.)
  label_syn = torch.tensor([np.ones(args.ipc) * i for i in range(num_classes)], dtype=torch.long, requires_grad=False,
Expert Dir: ../buffer_storage/MNIST\ConvNet
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_loss.py:177: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  buffer = torch.load(expert_files[expert_id[file_idx]])
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_loss.py:207: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  temp_params = torch.load(label_expert_files[0])[0][args.Label_Model_Timestamp]
0.0.0
1.0.0
2.0.0
3.0.0
4.0.0
5.0.0
6.0.0
7.0.0
8.0.0
9.0.0
[2024-11-06 02:10:27] training begins
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_loss.py:291: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  Temp_Buffer = torch.load(label_expert_files[i])
InitialAcc:1.0
C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\torch\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\TensorShape.cpp:3596.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[2024-11-06 02:10:28] iter = 0000, loss = 0.9679
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_loss.py:501: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  buffer = torch.load(expert_files[expert_id[file_idx]])
[2024-11-06 02:10:33] iter = 0010, loss = 0.8680
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:10:38] iter = 0020, loss = 0.9903
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:10:44] iter = 0030, loss = 2.5271
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:10:49] iter = 0040, loss = 0.9282
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:10:54] iter = 0050, loss = 0.7970
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:00] iter = 0060, loss = 1.3173
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:05] iter = 0070, loss = 0.7606
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:10] iter = 0080, loss = 0.6820
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:16] iter = 0090, loss = 0.9579
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:21] iter = 0100, loss = 0.6287
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:27] iter = 0110, loss = 0.8983
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:32] iter = 0120, loss = 0.5867
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:38] iter = 0130, loss = 0.7835
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:43] iter = 0140, loss = 1.8311
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:49] iter = 0150, loss = 0.6435
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:11:54] iter = 0160, loss = 0.8762
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:00] iter = 0170, loss = 0.9301
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:06] iter = 0180, loss = 0.8711
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:11] iter = 0190, loss = 0.8128
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:16] iter = 0200, loss = 0.8624
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:22] iter = 0210, loss = 0.7383
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:27] iter = 0220, loss = 0.9309
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:33] iter = 0230, loss = 1.2578
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:38] iter = 0240, loss = 0.6404
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:44] iter = 0250, loss = 0.5921
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:49] iter = 0260, loss = 0.6790
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:12:54] iter = 0270, loss = 0.6582
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:00] iter = 0280, loss = 0.5881
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:05] iter = 0290, loss = 0.5953
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:10] iter = 0300, loss = 0.8494
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:15] iter = 0310, loss = 0.8906
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:21] iter = 0320, loss = 0.9093
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:26] iter = 0330, loss = 2.4357
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:31] iter = 0340, loss = 2.1456
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:37] iter = 0350, loss = 0.7602
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:42] iter = 0360, loss = 0.5580
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:48] iter = 0370, loss = 0.8619
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:53] iter = 0380, loss = 0.5682
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:13:58] iter = 0390, loss = 3.5630
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:04] iter = 0400, loss = 1.4390
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:09] iter = 0410, loss = 0.7856
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:14] iter = 0420, loss = 0.7460
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:20] iter = 0430, loss = 0.6172
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:25] iter = 0440, loss = 0.5611
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:31] iter = 0450, loss = 0.8847
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:36] iter = 0460, loss = 0.5466
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:42] iter = 0470, loss = 2.8114
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:47] iter = 0480, loss = 0.8762
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:14:52] iter = 0490, loss = 2.7915
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
DSA augmentation strategy:
 color_crop_cutout_flip_scale_rotate
DSA augmentation parameters:
 {'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'ratio_noise': 0.05, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'batchmode': False, 'latestseed': -1}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1001/1001 [00:08<00:00, 114.24it/s]
[2024-11-06 02:15:06] Evaluate_00: epoch = 1000 train time = 8 s train loss = 0.061864 train acc = 0.1000, test acc = 0.7864
Evaluate 1 random ConvNet, mean = 0.7864 std = 0.0000
-------------------------
Device: cuda
Traceback (most recent call last):
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\shutil.py", line 853, in move
    os.rename(src, real_dst)
FileNotFoundError: [WinError 3] 系统找不到指定的路径。: 'C:\\Users\\Paul\\AppData\\Local\\Temp\\tmpb_0wmib_wandb-media\\xndkivs9.png' -> 'D:\\PersonalFile\\UofT\\Digital Image Processing and Application\\ProjectA\\ECE1512_2024F_ProjectA_submission_files\\submission_files\\PAD\\PAD\\distill\\wandb\\run-20241106_021024-61qv3emj\\files\\media\\images\\Clipped_Reconstructed_Images/std_2.5_500_ec0b6065807bb44332a1.png'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_loss.py", line 617, in <module>
    main(args)
  File "D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_loss.py", line 470, in main
    wandb.log({"Clipped_Reconstructed_Images/std_{}".format(clip_val): wandb.Image(
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 1930, in log
    self._log(data=data, step=step, commit=commit)
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 1649, in _log
    self._partial_history_callback(data, step, commit)
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 1521, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\interface\interface.py", line 631, in publish_partial_history
    data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\data_types\utils.py", line 54, in history_dict_to_json
    payload[key] = val_to_json(
                   ^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\data_types\utils.py", line 166, in val_to_json
    val.bind_to_run(run, key, namespace)
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\data_types\image.py", line 406, in bind_to_run
    super().bind_to_run(run, key, step, id_, ignore_copy_err=ignore_copy_err)
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\data_types\base_types\media.py", line 131, in bind_to_run
    shutil.move(self._path, new_path)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\shutil.py", line 873, in move
    copy_function(src, real_dst)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\shutil.py", line 448, in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\shutil.py", line 258, in copyfile
    with open(dst, 'wb') as fdst:
         ^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\PersonalFile\\UofT\\Digital Image Processing and Application\\ProjectA\\ECE1512_2024F_ProjectA_submission_files\\submission_files\\PAD\\PAD\\distill\\wandb\\run-20241106_021024-61qv3emj\\files\\media\\images\\Clipped_Reconstructed_Images/std_2.5_500_ec0b6065807bb44332a1.png'
