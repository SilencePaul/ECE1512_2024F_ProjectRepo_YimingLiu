Distributed training:  False
Hyper-parameters:
 {'cfg': '../configs/MNIST/IPC1.yaml', 'dataset': 'MNIST', 'subset': 'imagenette', 'model': 'ConvNet', 'ipc': 1, 'eval_mode': 'S', 'num_eval': 1, 'eval_it': 500, 'epoch_eval_train': 1000, 'Iteration': 5000, 'lr_img': 100, 'lr_teacher': 0.01, 'lr_init': 0.01, 'batch_real': 256, 'batch_syn': 500, 'batch_train': 128, 'pix_init': 'samples_predicted_correctly', 'dsa': True, 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '../dataset', 'buffer_path': '../buffer_storage/', 'expert_epochs': 1, 'syn_steps': 40, 'max_start_epoch': 4, 'min_start_epoch': 0, 'zca': True, 'load_all': False, 'no_aug': False, 'texture': False, 'canvas_size': 2, 'canvas_samples': 1, 'max_files': None, 'max_experts': None, 'force_save': False, 'ema_decay': 0.995, 'lr_y': 5.0, 'Momentum_y': 0.9, 'project': 'MNIST_ipc1', 'name': 'RANDOM', 'threshold': 1.05, 'loss_ratio': 0.25, 'depth_ratio': 0.25, 'record_loss': False, 'Sequential_Generation': True, 'expansion_end_epoch': 3000, 'current_max_start_epoch': 20, 'init_frozen': 'start', 'skip_first_eva': True, 'parall_eva': False, 'lr_lr': 1e-07, 'res': 32, 'device': 'cuda', 'Initialize_Label_With_Another_Model': False, 'Initialize_Label_Model': '', 'Initialize_Label_Model_Dir': '', 'Label_Model_Timestamp': -1, 'zca_trans': ZCAWhitening(), 'im_size': [28, 28], 'dc_aug_param': None, 'dsa_param': <utils.utils_baseline.ParamDiffAug object at 0x0000023929672990>, '_wandb': {}, 'distributed': False}
Evaluation model pool:  ['ConvNet']
BUILDING DATASET
  0%|                                                                                                                                                                                                  | 0/60000 [00:00<?, ?it/s]D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_depth.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels_all.append(class_map[torch.tensor(sample[1]).item()])
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60000/60000 [00:00<00:00, 71175.99it/s]
60000it [00:00, 1064990.16it/s]
class c = 0: 5923 real images
class c = 1: 6742 real images
class c = 2: 5958 real images
class c = 3: 6131 real images
class c = 4: 5842 real images
class c = 5: 5421 real images
class c = 6: 5918 real images
class c = 7: 6265 real images
class c = 8: 5851 real images
class c = 9: 5949 real images
real images channel 0, mean = -0.0000, std = 0.5891
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_depth.py:138: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\torch\csrc\utils\tensor_new.cpp:281.)
  label_syn = torch.tensor([np.ones(args.ipc) * i for i in range(num_classes)], dtype=torch.long, requires_grad=False,
Expert Dir: ../buffer_storage/MNIST\ConvNet
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_depth.py:178: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  buffer = torch.load(expert_files[expert_id[file_idx]])
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_depth.py:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  temp_params = torch.load(label_expert_files[0])[0][args.Label_Model_Timestamp]
0.0.0
1.0.0
2.0.0
3.0.0
4.0.0
5.0.0
6.0.0
7.0.0
8.0.0
9.0.0
[2024-11-06 01:59:33] training begins
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_depth.py:292: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  Temp_Buffer = torch.load(label_expert_files[i])
InitialAcc:1.0
C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\torch\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\TensorShape.cpp:3596.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[2024-11-06 01:59:35] iter = 0000, loss = 0.9399
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_depth.py:506: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  buffer = torch.load(expert_files[expert_id[file_idx]])
[2024-11-06 01:59:40] iter = 0010, loss = 0.8321
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 01:59:46] iter = 0020, loss = 0.9589
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 01:59:52] iter = 0030, loss = 2.5580
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 01:59:57] iter = 0040, loss = 0.8982
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:03] iter = 0050, loss = 0.7943
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:08] iter = 0060, loss = 2.5714
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:14] iter = 0070, loss = 0.7811
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:19] iter = 0080, loss = 0.6968
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:25] iter = 0090, loss = 0.9323
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:31] iter = 0100, loss = 0.5810
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:36] iter = 0110, loss = 0.8637
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:42] iter = 0120, loss = 0.5903
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:47] iter = 0130, loss = 0.7801
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:53] iter = 0140, loss = 2.0015
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:00:58] iter = 0150, loss = 0.6421
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:04] iter = 0160, loss = 0.8784
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:09] iter = 0170, loss = 0.8869
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:15] iter = 0180, loss = 0.8598
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:20] iter = 0190, loss = 0.7733
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:26] iter = 0200, loss = 0.8498
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:31] iter = 0210, loss = 0.7131
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:37] iter = 0220, loss = 0.8716
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:43] iter = 0230, loss = 2.7385
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:48] iter = 0240, loss = 0.6137
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:54] iter = 0250, loss = 0.5835
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:01:59] iter = 0260, loss = 0.6904
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:05] iter = 0270, loss = 0.6827
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:10] iter = 0280, loss = 0.6030
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:16] iter = 0290, loss = 0.5763
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:21] iter = 0300, loss = 0.8239
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:27] iter = 0310, loss = 0.8937
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:32] iter = 0320, loss = 0.8663
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:38] iter = 0330, loss = 3.9982
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:43] iter = 0340, loss = 2.4990
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:49] iter = 0350, loss = 0.7719
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:02:55] iter = 0360, loss = 0.5532
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:00] iter = 0370, loss = 0.8137
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:06] iter = 0380, loss = 0.5437
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:11] iter = 0390, loss = 2.9259
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:17] iter = 0400, loss = 1.2444
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:22] iter = 0410, loss = 0.7457
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:28] iter = 0420, loss = 0.7083
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:33] iter = 0430, loss = 0.5966
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:39] iter = 0440, loss = 0.5329
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:44] iter = 0450, loss = 0.8466
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:50] iter = 0460, loss = 0.5545
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:03:55] iter = 0470, loss = 2.4843
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:04:01] iter = 0480, loss = 0.8640
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
[2024-11-06 02:04:07] iter = 0490, loss = 2.4466
loading file ../buffer_storage/MNIST\ConvNet\replay_buffer_0.pt
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
DSA augmentation strategy:
 color_crop_cutout_flip_scale_rotate
DSA augmentation parameters:
 {'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'ratio_noise': 0.05, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'batchmode': False, 'latestseed': -1}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1001/1001 [00:08<00:00, 115.37it/s]
[2024-11-06 02:04:20] Evaluate_00: epoch = 1000 train time = 8 s train loss = 0.055051 train acc = 0.1000, test acc = 0.8124
Evaluate 1 random ConvNet, mean = 0.8224 std = 0.0000
-------------------------
Device: cuda
Traceback (most recent call last):
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\shutil.py", line 853, in move
    os.rename(src, real_dst)
FileNotFoundError: [WinError 3] 系统找不到指定的路径。: 'C:\\Users\\Paul\\AppData\\Local\\Temp\\tmprnvx5rr3wandb-media\\iijgl90z.png' -> 'D:\\PersonalFile\\UofT\\Digital Image Processing and Application\\ProjectA\\ECE1512_2024F_ProjectA_submission_files\\submission_files\\PAD\\PAD\\distill\\wandb\\run-20241106_015930-sixtwa2c\\files\\media\\images\\Clipped_Reconstructed_Images/std_2.5_500_aeef45cbbd436a55159e.png'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_depth.py", line 627, in <module>
    main(args)
  File "D:\PersonalFile\UofT\Digital Image Processing and Application\ProjectA\ECE1512_2024F_ProjectA_submission_files\submission_files\PAD\PAD\distill\PAD_depth.py", line 475, in main
    wandb.log({"Clipped_Reconstructed_Images/std_{}".format(clip_val): wandb.Image(
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 1930, in log
    self._log(data=data, step=step, commit=commit)
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 1649, in _log
    self._partial_history_callback(data, step, commit)
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\wandb_run.py", line 1521, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\interface\interface.py", line 631, in publish_partial_history
    data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\data_types\utils.py", line 54, in history_dict_to_json
    payload[key] = val_to_json(
                   ^^^^^^^^^^^^
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\data_types\utils.py", line 166, in val_to_json
    val.bind_to_run(run, key, namespace)
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\data_types\image.py", line 406, in bind_to_run
    super().bind_to_run(run, key, step, id_, ignore_copy_err=ignore_copy_err)
  File "C:\Users\Paul\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\wandb\sdk\data_types\base_types\media.py", line 131, in bind_to_run
    shutil.move(self._path, new_path)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\shutil.py", line 873, in move
    copy_function(src, real_dst)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\shutil.py", line 448, in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\shutil.py", line 258, in copyfile
    with open(dst, 'wb') as fdst:
         ^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\PersonalFile\\UofT\\Digital Image Processing and Application\\ProjectA\\ECE1512_2024F_ProjectA_submission_files\\submission_files\\PAD\\PAD\\distill\\wandb\\run-20241106_015930-sixtwa2c\\files\\media\\images\\Clipped_Reconstructed_Images/std_2.5_500_aeef45cbbd436a55159e.png'
